THREAD_COUNT = 1
OVERWRITE = True
RAISE_ERRORS = False
SAVE_PAGES = False
ZIP_FILES = False
OVERRIDE_SIZE = False
SAVE_WORDS = False
RESTRICT = True
DOMAIN = 'fpt.com.vn'
RESPECT_ROBOTS = True
TODO_FILE = 'output/crawler_todo.txt'
DONE_FILE = 'output/crawler_done.txt'
WORD_FILE = 'output/crawler_words.txt'
SAVE_COUNT = 100
HEADER = HEADERS['spidy']
MAX_NEW_ERRORS = 50
MAX_KNOWN_ERRORS = 50
MAX_HTTP_ERRORS = 20
MAX_NEW_MIMES = 10
START = ['https://www.fpt.com.vn']